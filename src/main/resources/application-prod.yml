server:
  port: 3500
  #port: ${random.int[3000,39999]}

kafka:
  topics:
    - name: job-serial
      num-partitions: 3
      replication-factor: 1
    - name: job-parallel
      num-partitions: 1
      replication-factor: 1

kubernetes:
  configs:
    - name: workflow
      master-url: https://10.10.10.131:6443
      kube-config: /root/.kube/config
      token: 7znlvu.cfno8z3yit4meue5
spring:
  application:
    name: WOEKFLOW
  kafka:
    bootstrap-servers: 10.10.10.133:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      enable-auto-commit: false # 使用 Spring-Kafka 的消费进度的提交机制
      properties:
        spring:
          json:
            trusted:
              packages: io.fabric8.kubernetes.api.model.batch
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错
      ack-mode: MANUAL

logging:
  level:
    com.whiskas68.cloud: INFO

